{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6aXebrzSjBB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q yt-dlp edge-tts moviepy git+https://github.com/openai/whisper.git requests\n",
        "\n",
        "import os, re, whisper, requests\n",
        "from moviepy.editor import VideoFileClip, CompositeVideoClip, AudioFileClip, ColorClip\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def descargar_fondo(keyword=\"abstract\", output_dir=\"/content/drive/MyDrive/drama-automation/fondos\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    safe_keyword = keyword.replace(\" \", \"_\")\n",
        "    ruta_fondo = f\"{output_dir}/fondo_{safe_keyword}.mp4\"\n",
        "\n",
        "    if os.path.exists(ruta_fondo):\n",
        "        print(f\"‚úÖ Fondo '{keyword}' ya existe.\")\n",
        "        return ruta_fondo\n",
        "\n",
        "    url = f\"https://api.pexels.com/videos/search?query={keyword}&per_page=1&orientation=vertical\"\n",
        "    headers = {\"Authorization\": userdata.get('PEXELS_API_KEY')}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if data.get(\"videos\"):\n",
        "            video = data[\"videos\"][0]\n",
        "            # Buscar archivo en SD o similar\n",
        "            for archivo in video[\"video_files\"]:\n",
        "                if archivo[\"quality\"] == \"sd\" or \"360\" in str(archivo.get(\"height\", \"\")):\n",
        "                    !wget -O \"{ruta_fondo}\" \"{archivo['link']}\"\n",
        "                    print(f\"‚úÖ Fondo '{keyword}' descargado.\")\n",
        "                    return ruta_fondo\n",
        "            # Fallback: primer archivo disponible\n",
        "            !wget -O \"{ruta_fondo}\" \"{video['video_files'][0]['link']}\"\n",
        "            print(f\"‚úÖ Fondo '{keyword}' descargado (calidad alternativa).\")\n",
        "            return ruta_fondo\n",
        "    print(f\"‚ùå No se encontr√≥ fondo para: {keyword}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "YoSWREhTBgR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/drama-automation\"\n",
        "URLS_FILE = f\"{BASE_DIR}/data/urls.txt\"\n",
        "TEMP_DIR = f\"{BASE_DIR}/temp\"\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# Leer enlaces y keywords\n",
        "with open(URLS_FILE, \"r\") as f:\n",
        "    lines = [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n",
        "\n",
        "dramas = []\n",
        "for line in lines:\n",
        "    if \"|\" in line:\n",
        "        url, keyword = line.split(\"|\", 1)\n",
        "        dramas.append((url.strip(), keyword.strip()))\n",
        "    else:\n",
        "        dramas.append((line.strip(), \"abstract\"))\n",
        "\n",
        "print(f\"üé¨ Se procesar√°n {len(dramas)} dramas.\")\n",
        "\n",
        "# Descargar dramas\n",
        "for i, (url, keyword) in enumerate(dramas):\n",
        "    print(f\"üì• Descargando drama {i+1}...\")\n",
        "    !yt-dlp -f \"best[height<=480]\" -o \"{TEMP_DIR}/drama_{i+1}.mp4\" \"{url}\"\n",
        "print(\"‚úÖ Todos los dramas descargados.\")"
      ],
      "metadata": {
        "id": "kK5Reeo6Bkeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n de Shorts\n",
        "SHORTS_TIMINGS = [\n",
        "    (\"00:01:10\", \"00:01:40\"), (\"00:03:20\", \"00:03:50\"), (\"00:05:45\", \"00:06:15\"),\n",
        "    (\"00:08:10\", \"00:08:40\"), (\"00:11:30\", \"00:12:00\"), (\"00:14:20\", \"00:14:50\"),\n",
        "    (\"00:17:10\", \"00:17:40\"), (\"00:20:05\", \"00:20:35\"), (\"00:23:40\", \"00:24:10\"),\n",
        "    (\"00:27:15\", \"00:27:45\")\n",
        "]\n",
        "\n",
        "# Cap√≠tulos para YouTube\n",
        "CAPITULOS = [\n",
        "    (\"00:00\", \"Introducci√≥n\"), (\"01:10\", \"El regreso inesperado\"), (\"03:20\", \"Secretos del pasado\"),\n",
        "    (\"05:45\", \"Primer enfrentamiento\"), (\"08:10\", \"La traici√≥n\"), (\"11:30\", \"L√°grimas de verdad\"),\n",
        "    (\"14:20\", \"Decisi√≥n final\"), (\"17:10\", \"Consecuencias\"), (\"20:05\", \"Nuevas alianzas\"),\n",
        "    (\"23:40\", \"El juramento\"), (\"27:15\", \"Final del cap√≠tulo 10\")\n",
        "]\n",
        "\n",
        "# Cargar Whisper\n",
        "model = whisper.load_model(\"small\")\n",
        "\n",
        "# Procesar cada drama\n",
        "drama_files = sorted([f for f in os.listdir(TEMP_DIR) if f.endswith(\".mp4\")])\n",
        "for drama_file in drama_files:\n",
        "    idx = int(drama_file.replace(\"drama_\", \"\").replace(\".mp4\", \"\"))\n",
        "    url, keyword = dramas[idx - 1]\n",
        "\n",
        "    drama_path = f\"{TEMP_DIR}/{drama_file}\"\n",
        "    output_dir = f\"{BASE_DIR}/output/drama_{idx}\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/shorts\", exist_ok=True)\n",
        "\n",
        "    print(f\"\\nüé• Procesando drama {idx} (fondo: {keyword})...\")\n",
        "\n",
        "    # --- 1. Transcripci√≥n ---\n",
        "    clip = VideoFileClip(drama_path)\n",
        "    clip.audio.write_audiofile(f\"{TEMP_DIR}/audio_{idx}.wav\", logger=None)\n",
        "    result = model.transcribe(f\"{TEMP_DIR}/audio_{idx}.wav\", language=\"es\")\n",
        "\n",
        "    # --- 2. TTS mejorado ---\n",
        "    raw_text = result[\"text\"]\n",
        "    guion = re.sub(r'\\.\\s*', '. <break time=\"600ms\"/> ', raw_text)\n",
        "    guion = re.sub(r',\\s*', ', <break time=\"300ms\"/> ', guion)\n",
        "    guion = \" \".join(guion.split())\n",
        "\n",
        "    tts_path = f\"{output_dir}/tts.mp3\"\n",
        "    !edge-tts --text \"{guion.replace('\"', '\\\\\"')}\" --voice es-ES-ElviraNeural --write-media \"{tts_path}\"\n",
        "\n",
        "    # --- 3. Subt√≠tulos ---\n",
        "    writer = whisper.utils.get_writer(\"srt\", output_dir)\n",
        "    writer(result, \"subtitulos.srt\")\n",
        "\n",
        "    # --- 4. Fondo autom√°tico ---\n",
        "    fondo_path = descargar_fondo(keyword=keyword)\n",
        "    if fondo_path:\n",
        "        fondo_clip = VideoFileClip(fondo_path).loop(duration=clip.duration)\n",
        "        fondo_clip = fondo_clip.resize(clip.size)\n",
        "    else:\n",
        "        fondo_clip = ColorClip(size=clip.size, color=(30,30,30), duration=clip.duration)\n",
        "\n",
        "    # --- 5. Video largo (16:9) ---\n",
        "    video_largo = CompositeVideoClip([fondo_clip.set_opacity(0.3), clip.without_audio()])\n",
        "    video_largo = video_largo.set_audio(AudioFileClip(tts_path))\n",
        "    video_largo.write_videofile(f\"{output_dir}/largo.mp4\", codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
        "\n",
        "    # --- 6. Shorts (9:16) ---\n",
        "    for j, (start, end) in enumerate(SHORTS_TIMINGS):\n",
        "        try:\n",
        "            sub = clip.subclip(start, end)\n",
        "            sub = sub.resize(height=1920).crop(x_center=sub.w/2, width=1080)\n",
        "            sub.write_videofile(f\"{output_dir}/shorts/short_{j+1}.mp4\", fps=24, audio=False, logger=None)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Short {j+1} omitido: {str(e)[:50]}\")\n",
        "\n",
        "    # --- 7. Cap√≠tulos ---\n",
        "    with open(f\"{output_dir}/capitulos.txt\", \"w\") as f:\n",
        "        for t, title in CAPITULOS:\n",
        "            f.write(f\"{t} - {title}\\n\")\n",
        "\n",
        "print(\"\\nüéâ ¬°Procesamiento completado! Revisa la carpeta /output\")"
      ],
      "metadata": {
        "id": "cwgq9rT7Bm1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_path = f\"{BASE_DIR}/output/dramas_completos.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\") as zf:\n",
        "    for root, _, files in os.walk(f\"{BASE_DIR}/output\"):\n",
        "        for file in files:\n",
        "            if file != \"dramas_completos.zip\":\n",
        "                full_path = os.path.join(root, file)\n",
        "                arc_path = os.path.relpath(full_path, f\"{BASE_DIR}/output\")\n",
        "                zf.write(full_path, arc_path)\n",
        "print(f\"üì¶ Resultados empaquetados: {zip_path}\")"
      ],
      "metadata": {
        "id": "1hAh-8JtBpb2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}