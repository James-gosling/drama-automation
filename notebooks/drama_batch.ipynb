{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6aXebrzSjBB"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install -q yt-dlp edge-tts moviepy git+https://github.com/openai/whisper.git requests\n",
    "\n",
    "import os, re, whisper, requests, hashlib, pickle\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, AudioFileClip, ColorClip\n",
    "from google.colab import userdata\n",
    "import gc  # For memory management\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def descargar_fondo(keyword=\"abstract\", output_dir=\"/content/drive/MyDrive/drama-automation/fondos\"):\n",
    "    \"\"\"Download background video with caching and error handling.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    safe_keyword = keyword.replace(\" \", \"_\")\n",
    "    ruta_fondo = f\"{output_dir}/fondo_{safe_keyword}.mp4\"\n",
    "\n",
    "    # Check cache first\n",
    "    if os.path.exists(ruta_fondo):\n",
    "        print(f\"\u2705 Fondo '{keyword}' ya existe (usando cach\u00e9).\")\n",
    "        return ruta_fondo\n",
    "\n",
    "    url = f\"https://api.pexels.com/videos/search?query={keyword}&per_page=1&orientation=vertical\"\n",
    "    headers = {\"Authorization\": userdata.get('PEXELS_API_KEY')}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\u274c Error al conectar con Pexels: {e}\")\n",
    "        return None\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"videos\"):\n",
    "            video = data[\"videos\"][0]\n",
    "            # Buscar archivo en SD o similar (optimized)\n",
    "            for archivo in video[\"video_files\"]:\n",
    "                if archivo[\"quality\"] == \"sd\" or \"360\" in str(archivo.get(\"height\", \"\")):\n",
    "                    !wget -q -O \"{ruta_fondo}\" \"{archivo['link']}\"\n",
    "                    print(f\"\u2705 Fondo '{keyword}' descargado.\")\n",
    "                    return ruta_fondo\n",
    "            # Fallback: primer archivo disponible\n",
    "            !wget -q -O \"{ruta_fondo}\" \"{video['video_files'][0]['link']}\"\n",
    "            print(f\"\u2705 Fondo '{keyword}' descargado (calidad alternativa).\")\n",
    "            return ruta_fondo\n",
    "    print(f\"\u274c No se encontr\u00f3 fondo para: {keyword}\")\n",
    "    return None\n"
   ],
   "metadata": {
    "id": "YoSWREhTBgR2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BASE_DIR = \"/content/drive/MyDrive/drama-automation\"\n",
    "URLS_FILE = f\"{BASE_DIR}/data/urls.txt\"\n",
    "TEMP_DIR = f\"{BASE_DIR}/temp\"\n",
    "CACHE_DIR = f\"{BASE_DIR}/cache\"  # NEW: Cache directory\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Leer enlaces y keywords\n",
    "with open(URLS_FILE, \"r\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n",
    "\n",
    "dramas = []\n",
    "for line in lines:\n",
    "    if \"|\" in line:\n",
    "        url, keyword = line.split(\"|\", 1)\n",
    "        dramas.append((url.strip(), keyword.strip()))\n",
    "    else:\n",
    "        dramas.append((line.strip(), \"abstract\"))\n",
    "\n",
    "print(f\"\ud83c\udfac Se procesar\u00e1n {len(dramas)} dramas.\")\n",
    "\n",
    "# Descargar dramas\n",
    "for i, (url, keyword) in enumerate(dramas):\n",
    "    output_path = f\"{TEMP_DIR}/drama_{i+1}.mp4\"\n",
    "    if not os.path.exists(output_path):  # Skip if already downloaded\n",
    "        print(f\"\ud83d\udce5 Descargando drama {i+1}...\")\n",
    "        !yt-dlp -f \"best[height<=480]\" -o \"{output_path}\" \"{url}\"\n",
    "    else:\n",
    "        print(f\"\u2705 Drama {i+1} ya descargado (usando cach\u00e9).\")\n",
    "print(\"\u2705 Todos los dramas descargados.\")\n"
   ],
   "metadata": {
    "id": "kK5Reeo6Bkeh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuraci\u00f3n de Shorts\n",
    "SHORTS_TIMINGS = [\n",
    "    (\"00:01:10\", \"00:01:40\"), (\"00:03:20\", \"00:03:50\"), (\"00:05:45\", \"00:06:15\"),\n",
    "    (\"00:08:10\", \"00:08:40\"), (\"00:11:30\", \"00:12:00\"), (\"00:14:20\", \"00:14:50\"),\n",
    "    (\"00:17:10\", \"00:17:40\"), (\"00:20:05\", \"00:20:35\"), (\"00:23:40\", \"00:24:10\"),\n",
    "    (\"00:27:15\", \"00:27:45\")\n",
    "]\n",
    "\n",
    "# Cap\u00edtulos para YouTube\n",
    "CAPITULOS = [\n",
    "    (\"00:00\", \"Introducci\u00f3n\"), (\"01:10\", \"El regreso inesperado\"), (\"03:20\", \"Secretos del pasado\"),\n",
    "    (\"05:45\", \"Primer enfrentamiento\"), (\"08:10\", \"La traici\u00f3n\"), (\"11:30\", \"L\u00e1grimas de verdad\"),\n",
    "    (\"14:20\", \"Decisi\u00f3n final\"), (\"17:10\", \"Consecuencias\"), (\"20:05\", \"Nuevas alianzas\"),\n",
    "    (\"23:40\", \"El juramento\"), (\"27:15\", \"Final del cap\u00edtulo 10\")\n",
    "]\n",
    "\n",
    "def get_cache_key(file_path):\n",
    "    \"\"\"Generate cache key based on file path and modification time.\"\"\"\n",
    "    stat = os.stat(file_path)\n",
    "    return hashlib.md5(f\"{file_path}_{stat.st_mtime}_{stat.st_size}\".encode()).hexdigest()\n",
    "\n",
    "def get_cached_transcription(audio_path, cache_dir):\n",
    "    \"\"\"Load cached transcription if available.\"\"\"\n",
    "    cache_key = get_cache_key(audio_path)\n",
    "    cache_file = f\"{cache_dir}/transcription_{cache_key}.pkl\"\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "def save_transcription_cache(audio_path, result, cache_dir):\n",
    "    \"\"\"Save transcription to cache.\"\"\"\n",
    "    cache_key = get_cache_key(audio_path)\n",
    "    cache_file = f\"{cache_dir}/transcription_{cache_key}.pkl\"\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "\n",
    "def optimize_guion(text):\n",
    "    \"\"\"Optimized text processing with minimal regex calls.\"\"\"\n",
    "    # Single pass with combined regex patterns\n",
    "    text = re.sub(r'\\.\\s*', '. <break time=\"600ms\"/> ', text)\n",
    "    text = re.sub(r',\\s*', ', <break time=\"300ms\"/> ', text)\n",
    "    return \" \".join(text.split())  # Normalize whitespace\n",
    "\n",
    "# Cargar Whisper model ONCE (outside loop)\n",
    "print(\"\ud83d\udcda Cargando modelo Whisper...\")\n",
    "model = whisper.load_model(\"small\")\n",
    "\n",
    "# Procesar cada drama\n",
    "drama_files = sorted([f for f in os.listdir(TEMP_DIR) if f.endswith(\".mp4\")])\n",
    "for drama_file in drama_files:\n",
    "    idx = int(drama_file.replace(\"drama_\", \"\").replace(\".mp4\", \"\"))\n",
    "    url, keyword = dramas[idx - 1]\n",
    "\n",
    "    drama_path = f\"{TEMP_DIR}/{drama_file}\"\n",
    "    output_dir = f\"{BASE_DIR}/output/drama_{idx}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(f\"{output_dir}/shorts\", exist_ok=True)\n",
    "\n",
    "    print(f\"\\n\ud83c\udfa5 Procesando drama {idx} (fondo: {keyword})...\")\n",
    "\n",
    "    # --- 1. Transcripci\u00f3n con cach\u00e9 ---\n",
    "    audio_path = f\"{TEMP_DIR}/audio_{idx}.wav\"\n",
    "    \n",
    "    # Check cache first\n",
    "    result = get_cached_transcription(drama_path, CACHE_DIR)\n",
    "    \n",
    "    if result is None:\n",
    "        print(\"  \ud83d\udd04 Transcribiendo audio (no hay cach\u00e9)...\")\n",
    "        clip = VideoFileClip(drama_path)\n",
    "        clip.audio.write_audiofile(audio_path, logger=None)\n",
    "        clip.close()  # OPTIMIZATION: Release immediately\n",
    "        del clip\n",
    "        gc.collect()\n",
    "        \n",
    "        result = model.transcribe(audio_path, language=\"es\")\n",
    "        save_transcription_cache(drama_path, result, CACHE_DIR)\n",
    "    else:\n",
    "        print(\"  \u2705 Usando transcripci\u00f3n en cach\u00e9\")\n",
    "\n",
    "    # --- 2. TTS mejorado (optimized text processing) ---\n",
    "    guion = optimize_guion(result[\"text\"])\n",
    "    tts_path = f\"{output_dir}/tts.mp3\"\n",
    "    \n",
    "    if not os.path.exists(tts_path):  # Skip if already exists\n",
    "        !edge-tts --text \"{guion.replace('\"', '\\\\\"')}\" --voice es-ES-ElviraNeural --write-media \"{tts_path}\"\n",
    "    else:\n",
    "        print(\"  \u2705 Audio TTS ya existe (usando cach\u00e9)\")\n",
    "\n",
    "    # --- 3. Subt\u00edtulos ---\n",
    "    srt_path = f\"{output_dir}/subtitulos.srt\"\n",
    "    if not os.path.exists(srt_path):  # Skip if already exists\n",
    "        writer = whisper.utils.get_writer(\"srt\", output_dir)\n",
    "        writer(result, \"subtitulos.srt\")\n",
    "\n",
    "    # --- 4. Fondo autom\u00e1tico (con cach\u00e9) ---\n",
    "    fondo_path = descargar_fondo(keyword=keyword)\n",
    "\n",
    "    # --- 5. Video largo (16:9) ---\n",
    "    largo_path = f\"{output_dir}/largo.mp4\"\n",
    "    if not os.path.exists(largo_path):  # Skip if already exists\n",
    "        print(\"  \ud83c\udfac Creando video largo...\")\n",
    "        clip = VideoFileClip(drama_path)\n",
    "        \n",
    "        if fondo_path:\n",
    "            fondo_clip = VideoFileClip(fondo_path).loop(duration=clip.duration)\n",
    "            fondo_clip = fondo_clip.resize(clip.size)\n",
    "        else:\n",
    "            fondo_clip = ColorClip(size=clip.size, color=(30,30,30), duration=clip.duration)\n",
    "\n",
    "        video_largo = CompositeVideoClip([fondo_clip.set_opacity(0.3), clip.without_audio()])\n",
    "        video_largo = video_largo.set_audio(AudioFileClip(tts_path))\n",
    "        video_largo.write_videofile(largo_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
    "        \n",
    "        # OPTIMIZATION: Clean up resources\n",
    "        video_largo.close()\n",
    "        fondo_clip.close()\n",
    "        clip.close()\n",
    "        del video_largo, fondo_clip, clip\n",
    "        gc.collect()\n",
    "    else:\n",
    "        print(\"  \u2705 Video largo ya existe (usando cach\u00e9)\")\n",
    "\n",
    "    # --- 6. Shorts (9:16) - Optimized loading ---\n",
    "    print(\"  \u2702\ufe0f Creando shorts...\")\n",
    "    # Load clip ONCE for all shorts\n",
    "    clip = VideoFileClip(drama_path)\n",
    "    \n",
    "    for j, (start, end) in enumerate(SHORTS_TIMINGS):\n",
    "        short_path = f\"{output_dir}/shorts/short_{j+1}.mp4\"\n",
    "        if os.path.exists(short_path):  # Skip if exists\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # OPTIMIZATION: Extract subclip without reloading\n",
    "            sub = clip.subclip(start, end)\n",
    "            sub = sub.resize(height=1920).crop(x_center=sub.w/2, width=1080)\n",
    "            sub.write_videofile(short_path, fps=24, audio=False, logger=None)\n",
    "            sub.close()  # Release immediately\n",
    "            del sub\n",
    "        except Exception as e:\n",
    "            print(f\"  \u26a0\ufe0f Short {j+1} omitido: {str(e)[:50]}\")\n",
    "    \n",
    "    # OPTIMIZATION: Close clip after all shorts\n",
    "    clip.close()\n",
    "    del clip\n",
    "    gc.collect()\n",
    "\n",
    "    # --- 7. Cap\u00edtulos ---\n",
    "    with open(f\"{output_dir}/capitulos.txt\", \"w\") as f:\n",
    "        for t, title in CAPITULOS:\n",
    "            f.write(f\"{t} - {title}\\n\")\n",
    "    \n",
    "    # OPTIMIZATION: Clean up temporary audio file\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "\n",
    "print(\"\\n\ud83c\udf89 \u00a1Procesamiento completado! Revisa la carpeta /output\")\n"
   ],
   "metadata": {
    "id": "cwgq9rT7Bm1p"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "zip_path = f\"{BASE_DIR}/output/dramas_completos.zip\"\n",
    "output_path = Path(f\"{BASE_DIR}/output\")\n",
    "\n",
    "print(\"\ud83d\udce6 Empaquetando resultados...\")\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:  # Use compression\n",
    "    # OPTIMIZATION: Use Path.rglob for efficient traversal\n",
    "    for file_path in output_path.rglob(\"*\"):\n",
    "        if file_path.is_file() and file_path.name != \"dramas_completos.zip\":\n",
    "            arc_path = file_path.relative_to(output_path)\n",
    "            zf.write(file_path, arc_path)\n",
    "            \n",
    "print(f\"\u2705 Resultados empaquetados: {zip_path}\")\n",
    "print(f\"\ud83d\udcca Tama\u00f1o del archivo: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n"
   ],
   "metadata": {
    "id": "1hAh-8JtBpb2"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}